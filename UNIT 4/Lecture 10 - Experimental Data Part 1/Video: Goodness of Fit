How good are these fits
-relative to each other
-in an absolute sense

Relative to Each Other
-fit is a fucntion of the independent variable to dependent variable
-given independent, provides estimate of dependent
-which fit provides better estimates

In an Absolute Sense
-useful for getting sense of absolute goodness of fit? is 1524 good
-hard to know since no upper bound not scale independent
-instead we use coefficient of determination, R^2

R^2 = 1 - Sumi(yi - pi)^2 / Sumi(yi - mean)^2
-by comparing estimation errors(num) with variabiltiy of original values (denom),
R^2 is intended to capture proportion of variability in a data set that is accounted for by 
statistical model provided by the fit
-always between 0 and 1 when fit generated by a linear regression and tested on training data
-if R^2 = 1 the model explains all variability

# xVals, yVals = getData('mysteryData.txt')
# pylab.plot(xVals, yVals, 'o', label = 'Data Points')
# pylab.title('Mystery Data')

# #Try linear model
# model1 = pylab.polyfit(xVals, yVals, 1)
# pylab.plot(xVals, pylab.polyval(model1, xVals),
#           label = 'Linear Model')

# #Try a quadratic model
# model2 = pylab.polyfit(xVals, yVals, 2)
# pylab.plot(xVals, pylab.polyval(model2, xVals),
#           'r--', label = 'Quadratic Model')
# pylab.legend()

# #Compare models
# def aveMeanSquareError(data, predicted):
#     error = 0.0
#     for i in range(len(data)):
#         error += (data[i] - predicted[i])**2
#     return error/len(data)

# estYVals = pylab.polyval(model1, xVals)  
# print('Ave. mean square error for linear model =',
#       aveMeanSquareError(yVals, estYVals))
# estYVals = pylab.polyval(model2, xVals)
# print('Ave. mean square error for quadratic model =',
#       aveMeanSquareError(yVals, estYVals))

def rSquared(observed, predicted):
    error = ((predicted - observed)**2).sum()
    meanError = error/len(observed)
    return 1 - (meanError/numpy.var(observed))

def genFits(xVals, yVals, degrees):
    models = []
    for d in degrees:
        model = pylab.polyfit(xVals, yVals, d)
        models.append(model)
    return models

def testFits(models, degrees, xVals, yVals, title):
    pylab.plot(xVals, yVals, 'o', label = 'Data')
    for i in range(len(models)):
        estYVals = pylab.polyval(models[i], xVals)
        error = rSquared(yVals, estYVals)
        pylab.plot(xVals, estYVals,
                   label = 'Fit of degree '\
                   + str(degrees[i])\
                   + ', R2 = ' + str(round(error, 5)))
    pylab.legend(loc = 'best')
    pylab.title(title)

xVals, yVals = getData('mysteryData.txt')
# degrees = (1, 2)
# models = genFits(xVals, yVals, degrees)
# testFits(models, degrees, xVals, yVals, 'Mystery Data')

#Compare higher-order fits
degrees = (2, 4, 8, 16)
models = genFits(xVals, yVals, degrees)
testFits(models, degrees, xVals, yVals, 'Mystery Data')

